{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spatial-egyptian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "data=pd.read_csv(\"mnist_train.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "external-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,MaxPooling2D,Conv2D,Dropout,Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "contained-brazilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17e4a1ec088>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANR0lEQVR4nO3dX4xc5X3G8efxsjbBCYrX1M7GOEAJlkor1VSLqeJAqUgRQakMSoJiKakroToXsRSkXEBpq1DloiRqQqM2QnLAjVMloFQJwhckxVgoCCVyvBAX2zUthBowdr1OncgmmPWf/fViD9Vids6M55yZM97f9yONZva8c+Y8GvnxmZ13Zl9HhADMffOaDgCgPyg7kARlB5Kg7EASlB1I4rx+Hmy+F8T5WtjPQwKpvKnf6ERMeraxSmW3fZOkr0sakvRARNxbdv/ztVDX+IYqhwRQYntsaznW9ct420OSviHpo5KulLTW9pXdPh6A3qryO/sqSS9GxEsRcULSw5LW1BMLQN2qlH2ZpFdn/Ly/2PY2ttfbHrc9flKTFQ4HoIoqZZ/tTYB3fPY2IjZGxFhEjA1rQYXDAaiiStn3S1o+4+eLJR2oFgdAr1Qp+w5JV9i+zPZ8SZ+StKWeWADq1vXUW0Scsr1B0r9peuptU0TsqS0ZgFpVmmePiMckPVZTFgA9xMdlgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSKLSKq7AIPvNJ65pOfblr9xfuu+Xbvuz0vEY391VpiZVKrvtfZKOSTot6VREjNURCkD96jiz/3FE/LKGxwHQQ/zODiRRtewh6XHbz9heP9sdbK+3PW57/KQmKx4OQLeqvoxfHREHbC+RtNX28xHx1Mw7RMRGSRsl6UKPRMXjAehSpTN7RBworickPSJpVR2hANSv67LbXmj7PW/dlnSjpHNvPgJIosrL+KWSHrH91uN8NyJ+VEuqHji+pvxFx/HFQ6XjI5t+Wmcc9MHEWOtz2Zf2/WkfkwyGrsseES9J+v0aswDoIabegCQoO5AEZQeSoOxAEpQdSCLNV1wPXFf+/9oFl/+6/AE21ZcFNZlXPl0aHzjecuyGJc+X7rvNH+oq0iDjzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSaSZZ//bj/1r6fiX997YpySoy9Dll5SOP/9HrT8csfJnny7d9/07dnWVaZBxZgeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJNLMsw/7VNMRULPzHnij632P/+LCGpOcGzizA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASc2aeferDK0vHrz3/6f4EQd9cuvB/u953+ROna0xybmh7Zre9yfaE7d0zto3Y3mr7heJ6UW9jAqiqk5fx35J00xnb7pK0LSKukLSt+BnAAGtb9oh4StKRMzavkbS5uL1Z0i31xgJQt27foFsaEQclqbhe0uqOttfbHrc9flKTXR4OQFU9fzc+IjZGxFhEjA1rQa8PB6CFbst+yPaoJBXXE/VFAtAL3ZZ9i6R1xe11kh6tJw6AXmk7z277IUnXS7rI9n5JX5R0r6Tv2b5d0iuSPtnLkJ14+WPvKh1fMnRBn5KgLudd+oHS8U+MbOn6sd/1378qHZ+Ls/Btyx4Ra1sM3VBzFgA9xMdlgSQoO5AEZQeSoOxAEpQdSGLOfMX1vA8eq7T/m8+/t54gqM2r/7CwdHz1gqnS8QePXtx68NdHu4l0TuPMDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJzJl59qqWjJfP2WJ2QxctLh0/9PEVLcdGbttfuu+PVzzY5ujnl47e/41bWo4tOfSTNo8993BmB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkmGcvHB8p/3+v/JvV1Uxde1XpeAy5dPzVj7ReaefE+0+W7jtvfvkfTX782n8sHR8uj6b/Od0629+8dGvpvkemyj/7cMG88uxLt7f+GwdRuufcxJkdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5KYM/Psk28Ol45PtZlZ/ee77ysd37Jh5dlG6tidix8oHZ+n8sns43Gi5diB0+Vz0f90+PrS8Y88cUfp+Ht/Pr90fPTxQy3H/HL599kP7y1fhnvpUPlnCGLHrtLxbNqe2W1vsj1he/eMbffYfs32zuJyc29jAqiqk5fx35J00yzb74uIlcXlsXpjAahb27JHxFOSjvQhC4AeqvIG3QbbzxUv8xe1upPt9bbHbY+f1GSFwwGootuy3y/pckkrJR2U9NVWd4yIjRExFhFjw2r9pQgAvdVV2SPiUEScjogpSd+UtKreWADq1lXZbY/O+PFWSbtb3RfAYGg7z277IUnXS7rI9n5JX5R0ve2Vmv5a8D5Jn+1dxM588NM/Lx3/3b/bUDq+/OrX6oxzVp6caP231SXp8A9L1hmXtHhP6/nm+T/a0ebo5XPVKzTeZv9yZbP8r935odJ9r17w09Lxh19f1kWivNqWPSLWzrK53V/vBzBg+LgskARlB5Kg7EASlB1IgrIDScyZr7i2c9lflk/jDLJRvdJ0hJ644LrDlfb/6yc/Xjq+Qj+r9PhzDWd2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUgizTw75p5LHs248HL3OLMDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEnyfHQNryOXnol+tGC4df98P60xz7mt7Zre93PaTtvfa3mP788X2Edtbbb9QXC/qfVwA3erkZfwpSV+IiN+R9IeSPmf7Skl3SdoWEVdI2lb8DGBAtS17RByMiGeL28ck7ZW0TNIaSZuLu22WdEuPMgKowVm9QWf7UklXSdouaWlEHJSm/0OQtKTFPuttj9seP6nJinEBdKvjstt+t6TvS7ojIo52ul9EbIyIsYgYG9aCbjICqEFHZbc9rOmifyciflBsPmR7tBgflTTRm4gA6tDJu/GW9KCkvRHxtRlDWyStK26vk/Ro/fGQ2emYKr1onsoveJtO5tlXS/qMpF22dxbb7pZ0r6Tv2b5d0iuSPtmThABq0bbsEfG0JLcYvqHeOAB6hRc7QBKUHUiCsgNJUHYgCcoOJMFXXHHOeuPqN5qOcE7hzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSTDPjoHV7k9J4+zwbAJJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEsyzozGTT/xW6fjplVN9SpIDZ3YgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSMIRUX4He7mkb0t6n6QpSRsj4uu275H0F5IOF3e9OyIeK3usCz0S15iFX4Fe2R7bdDSOzLrqcicfqjkl6QsR8azt90h6xvbWYuy+iPj7uoIC6J1O1mc/KOlgcfuY7b2SlvU6GIB6ndXv7LYvlXSVpO3Fpg22n7O9yfaiFvustz1ue/ykJqulBdC1jstu+92Svi/pjog4Kul+SZdLWqnpM/9XZ9svIjZGxFhEjA1rQfXEALrSUdltD2u66N+JiB9IUkQciojTETEl6ZuSVvUuJoCq2pbdtiU9KGlvRHxtxvbRGXe7VdLu+uMBqEsn78avlvQZSbts7yy23S1pre2VkkLSPkmf7UE+ADXp5N34pyXNNm9XOqcOYLDwCTogCcoOJEHZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASbf+UdK0Hsw9LennGposk/bJvAc7OoGYb1FwS2bpVZ7ZLImLWtbD7WvZ3HNwej4ixxgKUGNRsg5pLIlu3+pWNl/FAEpQdSKLpsm9s+PhlBjXboOaSyNatvmRr9Hd2AP3T9JkdQJ9QdiCJRspu+ybb/2n7Rdt3NZGhFdv7bO+yvdP2eMNZNtmesL17xrYR21ttv1Bcz7rGXkPZ7rH9WvHc7bR9c0PZltt+0vZe23tsf77Y3uhzV5KrL89b339ntz0k6b8k/Ymk/ZJ2SFobEf/R1yAt2N4naSwiGv8Ahu3rJL0u6dsR8XvFtq9IOhIR9xb/US6KiDsHJNs9kl5vehnvYrWi0ZnLjEu6RdKfq8HnriTXberD89bEmX2VpBcj4qWIOCHpYUlrGsgx8CLiKUlHzti8RtLm4vZmTf9j6bsW2QZCRByMiGeL28ckvbXMeKPPXUmuvmii7MskvTrj5/0arPXeQ9Ljtp+xvb7pMLNYGhEHpel/PJKWNJznTG2X8e6nM5YZH5jnrpvlz6tqouyzLSU1SPN/qyPiDyR9VNLniper6ExHy3j3yyzLjA+Ebpc/r6qJsu+XtHzGzxdLOtBAjllFxIHiekLSIxq8pagPvbWCbnE90XCe/zdIy3jPtsy4BuC5a3L58ybKvkPSFbYvsz1f0qckbWkgxzvYXli8cSLbCyXdqMFbinqLpHXF7XWSHm0wy9sMyjLerZYZV8PPXePLn0dE3y+Sbtb0O/K/kPRXTWRokeu3Jf17cdnTdDZJD2n6Zd1JTb8iul3SYknbJL1QXI8MULZ/kbRL0nOaLtZoQ9k+rOlfDZ+TtLO43Nz0c1eSqy/PGx+XBZLgE3RAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kMT/AT3d83+88ik1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Just check how the data look like here checking data in 3rd row and first column\n",
    "check=data.iloc[2,1:].values.reshape(28,28).astype('uint8')\n",
    "plt.imshow(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-rubber",
   "metadata": {},
   "source": [
    "# CNN using mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "japanese-beginning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "#split data for training and testing\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "responsible-nickname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#2D Convolution operation requires the input shape of image to be a 4D. But mnist is 3D shape array.\n",
    "x_train=x_train.reshape(-1,28,28,1).astype('float32')\n",
    "print(x_train.shape)\n",
    "x_test=x_test.reshape(-1,28,28,1).astype('float32')\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cognitive-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize our image data by normalizing the pixel \n",
    "#values of grayscale image that is by rescaling it to [0,1] range.\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "still-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using one hot encoding to convert this integer value(0-9) into a 10 channel one hot vector\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "y_train=np_utils.to_categorical(y_train,10)\n",
    "y_test=np_utils.to_categorical(y_test,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-moderator",
   "metadata": {},
   "source": [
    "# CNN Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "beautiful-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model=Sequential()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "assured-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,kernel_size=(3,3),input_shape=(x_train.shape[1:]),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "discrete-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "#categorical cross entropy loss function which is best for multi-class classification problem\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',  optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "durable-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 54s 906us/step - loss: 0.0697 - accuracy: 0.9786 - val_loss: 0.0451 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.06969, saving model to mnist_saved.hdf5\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 52s 871us/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.0310 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00002: loss improved from 0.06969 to 0.04284, saving model to mnist_saved.hdf5\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 0.0344 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00003: loss improved from 0.04284 to 0.03104, saving model to mnist_saved.hdf5\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 55s 914us/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0286 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 00004: loss improved from 0.03104 to 0.02439, saving model to mnist_saved.hdf5\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 54s 894us/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.0313 - val_accuracy: 0.9904\n",
      "\n",
      "Epoch 00005: loss improved from 0.02439 to 0.02031, saving model to mnist_saved.hdf5\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 54s 899us/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0331 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00006: loss improved from 0.02031 to 0.01602, saving model to mnist_saved.hdf5\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 53s 886us/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0267 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00007: loss improved from 0.01602 to 0.01505, saving model to mnist_saved.hdf5\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 53s 877us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0288 - val_accuracy: 0.9911\n",
      "\n",
      "Epoch 00008: loss improved from 0.01505 to 0.01262, saving model to mnist_saved.hdf5\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 53s 882us/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0346 - val_accuracy: 0.9904\n",
      "\n",
      "Epoch 00009: loss improved from 0.01262 to 0.01056, saving model to mnist_saved.hdf5\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 53s 879us/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0268 - val_accuracy: 0.9928\n",
      "\n",
      "Epoch 00010: loss improved from 0.01056 to 0.00925, saving model to mnist_saved.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath='mnist_saved.hdf5'\n",
    "Model_checkpoint=ModelCheckpoint(filepath,monitor='loss',verbose=1,save_best_only=True,mode='min')\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[Model_checkpoint],validation_data=(x_test, y_test), batch_size=32)\n",
    "# save the model\n",
    "file='mnist_saved.hdf5'\n",
    "model.load_weights(file)\n",
    "#recompile\n",
    "model.compile(loss='categorical_crossentropy',  optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "worth-gamma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026800465494919445\n",
      "Test accuracy: 0.9927999973297119\n",
      "0.9873481002596348\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on test data\n",
    "score = model.evaluate(x_test, y_test, verbose = 0) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# predicting on the test data\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "#r2_score value\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-speed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
